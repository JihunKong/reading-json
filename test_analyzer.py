#!/usr/bin/env python3
"""
Test the Korean Sentence Analyzer for summary learning system
"""

import sys
import os
sys.path.append('/Users/jihunkong/reading-json')

from core.nlp.korean_analyzer import KoreanSentenceAnalyzer, SentenceAnalysis

def test_comprehensive_analysis():
    """Test comprehensive sentence analysis functionality"""
    
    print("=== Korean Sentence Analyzer Test ===\n")
    
    # Initialize analyzer
    analyzer = KoreanSentenceAnalyzer()
    
    # Test sentences with different complexity levels
    test_sentences = [
        "ë¯¼ì£¼ì£¼ì˜ëŠ” ììœ ì™€ í‰ë“±ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬íšŒì  ì˜í–¥ë ¥ì„ í–‰ì‚¬í•˜ëŠ” ê°•ë ¥í•œ í˜ì´ë‹¤.",
        "ì±…ì„ ì½ëŠ”ë‹¤.",
        "í•™ìƒë“¤ì´ ë„ì„œê´€ì—ì„œ ì—´ì‹¬íˆ ê³µë¶€í•˜ê³  ìˆë‹¤.",
        "í˜„ëŒ€ ì‚¬íšŒì—ì„œ ê³¼í•™ ê¸°ìˆ ì˜ ë°œì „ì€ ì¸ê°„ì˜ ì‚¶ì„ í¬ê²Œ ë³€í™”ì‹œì¼°ë‹¤."
    ]
    
    for i, sentence in enumerate(test_sentences, 1):
        print(f"ğŸ“ Test Sentence {i}: {sentence}")
        print("-" * 60)
        
        try:
            # Analyze sentence
            analysis = analyzer.analyze_sentence(sentence)
            
            # Display results
            print(f"ğŸ¯ Main Concept: {analysis.main_concept}")
            print(f"ğŸ“Š Sentence Role: {analysis.sentence_role}")
            print(f"â­ Importance Score: {analysis.importance_score:.2f}")
            print(f"ğŸ” Complexity: {analysis.complexity_level}")
            
            print("\nğŸ“‹ Grammatical Components:")
            for comp_type, components in analysis.components.items():
                if components:
                    print(f"  {comp_type}:")
                    for comp in components:
                        necessity_emoji = "ğŸ”´" if comp.necessity == "required" else "ğŸŸ¡" if comp.necessity == "optional" else "âšª"
                        print(f"    {necessity_emoji} {comp.text} (importance: {comp.importance_score:.2f})")
            
            # Test summary component extraction
            summary_components = analyzer.extract_summary_components(analysis)
            print(f"\nğŸ“ Summary Components:")
            print(f"  Essential: {summary_components['essential']}")
            print(f"  Optional: {summary_components['optional']}")
            print(f"  Removable: {summary_components['removable']}")
            
            # Test learning hints with a sample user attempt
            user_summary = sentence[:10] + "..."  # Simplified mock summary
            hints = analyzer.generate_learning_hints(analysis, user_summary)
            if hints:
                print(f"\nğŸ’¡ Learning Hints:")
                for hint in hints:
                    print(f"  â€¢ {hint}")
            
        except Exception as e:
            print(f"âŒ Error analyzing sentence: {e}")
            import traceback
            traceback.print_exc()
        
        print("\n" + "="*80 + "\n")
    
    # Test paragraph analysis
    print("ğŸ“„ Paragraph Analysis Test:")
    paragraph = """
    ë¯¼ì£¼ì£¼ì˜ëŠ” ììœ ì™€ í‰ë“±ì„ ë°”íƒ•ìœ¼ë¡œ í•˜ëŠ” ì •ì¹˜ ì²´ì œì´ë‹¤. 
    ì‹œë¯¼ë“¤ì˜ ì ê·¹ì ì¸ ì°¸ì—¬ê°€ ë¯¼ì£¼ì£¼ì˜ì˜ í•µì‹¬ ìš”ì†Œì´ë‹¤.
    ë”°ë¼ì„œ ë¯¼ì£¼ì£¼ì˜ ì‚¬íšŒì—ì„œëŠ” ê°œì¸ì˜ ê¶Œë¦¬ì™€ ì±…ì„ì´ ê· í˜•ì„ ì´ë£¨ì–´ì•¼ í•œë‹¤.
    """.strip()
    
    try:
        paragraph_analyses = analyzer.analyze_paragraph(paragraph)
        
        print(f"ğŸ“Š Total sentences: {len(paragraph_analyses)}")
        for i, analysis in enumerate(paragraph_analyses, 1):
            print(f"  Sentence {i}: {analysis.sentence_role} (importance: {analysis.importance_score:.2f})")
            print(f"    Main concept: {analysis.main_concept}")
            print(f"    Text: {analysis.original_text}")
        
    except Exception as e:
        print(f"âŒ Error in paragraph analysis: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_comprehensive_analysis()