#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Golden Mini Dataset í…ŒìŠ¤íŠ¸

ì¤‘ì‹¬ë¬¸ì¥ ì„ íƒê³¼ í‚¤ì›Œë“œ ì¶”ì¶œì˜ ì •í™•ë„ë¥¼ ê²€ì¦í•˜ëŠ” ê³¨ë“  ìŠ¤íƒ ë‹¤ë“œ í…ŒìŠ¤íŠ¸ì…‹
"""

import pytest
import sys
import os

# ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '../generator'))
sys.path.append(os.path.join(os.path.dirname(__file__), '../validator'))
sys.path.append(os.path.join(os.path.dirname(__file__), '../grader'))

from topic_sentence import select_topic_sentence
from keywords import extract_keywords
from rule_validator import validate_content

# grader ëª¨ë“ˆì—ì„œ EnhancedGrader import
grader_path = os.path.join(os.path.dirname(__file__), '../grader')
sys.path.insert(0, grader_path)
from cli import EnhancedGrader


# Golden Mini Dataset (êµì‚¬ê°€ ìˆ˜ë™ìœ¼ë¡œ ë¼ë²¨ë§í•œ ì˜ˆì‹œ)
GOLDEN_CASES = [
    {
        "id": "golden_001",
        "sentences": [
            "ë„ì‹œ ë…¹í™”ëŠ” í™˜ê²½ ë¬¸ì œ í•´ê²°ì˜ í•µì‹¬ ë°©ë²•ì´ë‹¤.",  # ì •ë‹µ: ì¤‘ì‹¬ë¬¸ì¥
            "ë§ì€ ë„ì‹œë“¤ì´ ê³µì›ê³¼ ë…¹ì§€ ê³µê°„ì„ í™•ëŒ€í•˜ê³  ìˆë‹¤.",
            "ì´ëŸ¬í•œ ë…¸ë ¥ì€ ëŒ€ê¸° ì§ˆ ê°œì„ ê³¼ ì—´ì„¬ í˜„ìƒ ì™„í™”ì— ë„ì›€ì´ ëœë‹¤.",
            "ê²°ê³¼ì ìœ¼ë¡œ ì‹œë¯¼ë“¤ì˜ ì‚¶ì˜ ì§ˆì´ í–¥ìƒë˜ê³  ìˆë‹¤."
        ],
        "expected_topic_sentence": 0,  # ì²« ë²ˆì§¸ ë¬¸ì¥ì´ ì¤‘ì‹¬ë¬¸ì¥
        "expected_keywords": ["ë„ì‹œ", "ë…¹í™”", "í™˜ê²½", "ë¬¸ì œ", "í•´ê²°"],
        "genre": "ì„¤ëª…ë¬¸",
        "difficulty": "medium"
    },
    {
        "id": "golden_002",
        "sentences": [
            "ë””ì§€í„¸ ê¸°ìˆ ì˜ ë°œë‹¬ë¡œ êµìœ¡ ë°©ì‹ì´ ë³€í™”í•˜ê³  ìˆë‹¤.",
            "ì˜¨ë¼ì¸ ê°•ì˜ì™€ AI íŠœí„°ë§ ì‹œìŠ¤í…œì´ ë„ë¦¬ ë³´ê¸‰ë˜ì—ˆë‹¤.",
            "í•™ìŠµìë“¤ì€ ê°œì¸ ë§ì¶¤í˜• í•™ìŠµ ê²½í—˜ì„ ì œê³µë°›ëŠ”ë‹¤.",
            "ë”°ë¼ì„œ ë””ì§€í„¸ êµìœ¡ì€ ë¯¸ë˜ êµìœ¡ì˜ ì£¼ì¶•ì´ ë  ê²ƒì´ë‹¤."  # ì •ë‹µ: ê²°ë¡ ë¬¸ì¥ì´ ì¤‘ì‹¬
        ],
        "expected_topic_sentence": 3,  # ë§ˆì§€ë§‰ ë¬¸ì¥ì´ ì¤‘ì‹¬ë¬¸ì¥ (ê²°ë¡  ìš”ì•½)
        "expected_keywords": ["ë””ì§€í„¸", "êµìœ¡", "ê¸°ìˆ ", "í•™ìŠµ", "ë³€í™”"],
        "genre": "ë…¼ì„¤ë¬¸",
        "difficulty": "medium"
    },
    {
        "id": "golden_003",
        "sentences": [
            "ê¸°í›„ ë³€í™”ëŠ” ì „ ì§€êµ¬ì  ë¬¸ì œì´ë‹¤.",
            "ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ì´ ì§€ì†ì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ìˆë‹¤.",
            "ê·¹ì§€ë°©ì˜ ë¹™í•˜ê°€ ë…¹ê³  í•´ìˆ˜ë©´ì´ ìƒìŠ¹í•˜ê³  ìˆë‹¤.",
            "ì´ì— ëŒ€í•œ êµ­ì œì  í˜‘ë ¥ê³¼ ëŒ€ì‘ì´ ì‹œê¸‰í•˜ë‹¤."
        ],
        "expected_topic_sentence": 0,  # ì²« ë²ˆì§¸ ë¬¸ì¥ì´ ì£¼ì œë¬¸
        "expected_keywords": ["ê¸°í›„", "ë³€í™”", "ì§€êµ¬", "ì˜¨ì‹¤ê°€ìŠ¤", "ë¬¸ì œ"],
        "genre": "ì„¤ëª…ë¬¸",
        "difficulty": "hard"
    },
    {
        "id": "golden_004",
        "sentences": [
            "ì „í†µ ì‹œì¥ì€ ì§€ì—­ ê²½ì œì˜ ì¤‘ìš”í•œ ì¶•ì´ë‹¤.",
            "ìµœê·¼ ì˜¨ë¼ì¸ ì‡¼í•‘ ì¦ê°€ë¡œ ë§¤ì¶œì´ ê°ì†Œí•˜ê³  ìˆë‹¤.",
            "ì •ë¶€ì™€ ì§€ìì²´ê°€ ë‹¤ì–‘í•œ ì§€ì› ì •ì±…ì„ í¼ì¹˜ê³  ìˆë‹¤."
        ],
        "expected_topic_sentence": 0,  # ì²« ë²ˆì§¸ ë¬¸ì¥ì´ ì¤‘ì‹¬ë¬¸ì¥
        "expected_keywords": ["ì „í†µ", "ì‹œì¥", "ì§€ì—­", "ê²½ì œ", "ì¤‘ìš”"],
        "genre": "ì„¤ëª…ë¬¸",
        "difficulty": "easy"
    },
    {
        "id": "golden_005",
        "sentences": [
            "ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì´ ê¸‰ì†íˆ ë°œì „í•˜ê³  ìˆë‹¤.",
            "ì˜ë£Œ, ê¸ˆìœµ, êµìœ¡ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë˜ê³  ìˆë‹¤.",
            "í•˜ì§€ë§Œ ì¼ìë¦¬ ê°ì†Œì™€ ìœ¤ë¦¬ì  ë¬¸ì œê°€ ëŒ€ë‘ë˜ê³  ìˆë‹¤.",
            "ê²°êµ­ ì¸ê³µì§€ëŠ¥ê³¼ ì¸ê°„ì˜ í˜‘ë ¥ì  ê´€ê³„ êµ¬ì¶•ì´ ì¤‘ìš”í•˜ë‹¤."  # ì •ë‹µ: ê²°ë¡ ì´ ì¤‘ì‹¬
        ],
        "expected_topic_sentence": 3,  # ê²°ë¡  ë¬¸ì¥ì´ ì¤‘ì‹¬ë¬¸ì¥
        "expected_keywords": ["ì¸ê³µì§€ëŠ¥", "ê¸°ìˆ ", "ë°œì „", "í™œìš©", "í˜‘ë ¥"],
        "genre": "ë…¼ì„¤ë¬¸",
        "difficulty": "hard"
    }
]


class TestTopicSentenceSelection:
    """ì¤‘ì‹¬ë¬¸ì¥ ì„ íƒ í…ŒìŠ¤íŠ¸"""

    def test_topic_sentence_accuracy(self):
        """ì¤‘ì‹¬ë¬¸ì¥ ì„ íƒ ì •í™•ë„ í…ŒìŠ¤íŠ¸"""
        correct_count = 0
        total_count = len(GOLDEN_CASES)

        for case in GOLDEN_CASES:
            result = select_topic_sentence(
                sentences=case["sentences"],
                keywords=case["expected_keywords"],
                genre=case["genre"]
            )

            # Top-1 ì •í™•ë„ ì¸¡ì •
            if result.idx == case["expected_topic_sentence"]:
                correct_count += 1

            # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
            print(f"Case {case['id']}: Expected={case['expected_topic_sentence']}, "
                  f"Got={result.idx}, Score={result.total:.3f}")

        accuracy = correct_count / total_count
        print(f"Topic Sentence Accuracy: {accuracy:.2%} ({correct_count}/{total_count})")

        # ëª©í‘œ: 70% ì´ìƒ ì •í™•ë„
        assert accuracy >= 0.70, f"ì •í™•ë„ê°€ ëª©í‘œì¹˜(70%)ë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤: {accuracy:.2%}"

    def test_topic_sentence_top2_accuracy(self):
        """ì¤‘ì‹¬ë¬¸ì¥ Top-2 í¬í•¨ ì •í™•ë„ í…ŒìŠ¤íŠ¸"""
        top2_correct = 0
        total_count = len(GOLDEN_CASES)

        for case in GOLDEN_CASES:
            # ëª¨ë“  ë¬¸ì¥ì— ëŒ€í•´ ì ìˆ˜ ê³„ì‚°
            all_results = []
            for i in range(len(case["sentences"])):
                # ê° ë¬¸ì¥ì„ í›„ë³´ë¡œ í•´ì„œ ì ìˆ˜ ê³„ì‚°
                temp_sentences = case["sentences"].copy()
                result = select_topic_sentence(
                    sentences=temp_sentences,
                    keywords=case["expected_keywords"],
                    genre=case["genre"]
                )
                all_results.append((i, result.total))

            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
            all_results.sort(key=lambda x: x[1], reverse=True)
            top2_indices = [idx for idx, _ in all_results[:2]]

            if case["expected_topic_sentence"] in top2_indices:
                top2_correct += 1

        accuracy = top2_correct / total_count
        print(f"Topic Sentence Top-2 Accuracy: {accuracy:.2%} ({top2_correct}/{total_count})")

        # ëª©í‘œ: 88% ì´ìƒ Top-2 í¬í•¨
        assert accuracy >= 0.88, f"Top-2 ì •í™•ë„ê°€ ëª©í‘œì¹˜(88%)ë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤: {accuracy:.2%}"


class TestKeywordExtraction:
    """í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""

    def test_keyword_extraction_coverage(self):
        """í‚¤ì›Œë“œ ì¶”ì¶œ ì»¤ë²„ìœ¨ í…ŒìŠ¤íŠ¸"""
        total_coverage = 0
        total_count = len(GOLDEN_CASES)

        for case in GOLDEN_CASES:
            extracted = extract_keywords(case["sentences"], topk=8)
            expected = set(case["expected_keywords"])
            extracted_set = set(extracted)

            # ì»¤ë²„ìœ¨ ê³„ì‚° (êµì§‘í•© / ê¸°ëŒ€ê°’)
            coverage = len(expected & extracted_set) / len(expected) if expected else 0
            total_coverage += coverage

            print(f"Case {case['id']}: Expected={expected}, "
                  f"Extracted={extracted_set & expected}, Coverage={coverage:.2%}")

        avg_coverage = total_coverage / total_count
        print(f"Average Keyword Coverage: {avg_coverage:.2%}")

        # ëª©í‘œ: 60% ì´ìƒ í‚¤ì›Œë“œ ì»¤ë²„ìœ¨
        assert avg_coverage >= 0.60, f"í‚¤ì›Œë“œ ì»¤ë²„ìœ¨ì´ ëª©í‘œì¹˜(60%)ë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤: {avg_coverage:.2%}"

    def test_keyword_precision(self):
        """í‚¤ì›Œë“œ ì¶”ì¶œ ì •ë°€ë„ í…ŒìŠ¤íŠ¸ (ì¶”ì¶œëœ ê²ƒ ì¤‘ ì–¼ë§ˆë‚˜ ê´€ë ¨ì´ ìˆëŠ”ê°€)"""
        total_precision = 0
        total_count = len(GOLDEN_CASES)

        for case in GOLDEN_CASES:
            extracted = extract_keywords(case["sentences"], topk=5)

            # ê°„ë‹¨í•œ ê´€ë ¨ì„± ì²´í¬: ë¬¸ì¥ì— ì‹¤ì œë¡œ ë‚˜íƒ€ë‚˜ëŠ” ë‹¨ì–´ì¸ì§€
            full_text = " ".join(case["sentences"])
            relevant_count = 0

            for keyword in extracted:
                if keyword in full_text and len(keyword) >= 2:
                    relevant_count += 1

            precision = relevant_count / len(extracted) if extracted else 0
            total_precision += precision

        avg_precision = total_precision / total_count
        print(f"Average Keyword Precision: {avg_precision:.2%}")

        # ëª©í‘œ: 80% ì´ìƒ ì •ë°€ë„
        assert avg_precision >= 0.80, f"í‚¤ì›Œë“œ ì •ë°€ë„ê°€ ëª©í‘œì¹˜(80%)ë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤: {avg_precision:.2%}"


class TestContentValidation:
    """ì½˜í…ì¸  ê²€ì¦ í…ŒìŠ¤íŠ¸"""

    def test_content_quality(self):
        """ì½˜í…ì¸  í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        valid_count = 0
        total_count = len(GOLDEN_CASES)

        for case in GOLDEN_CASES:
            result = validate_content(
                sentences=case["sentences"],
                keywords=case["expected_keywords"]
            )

            if result.is_valid and result.score >= 0.7:
                valid_count += 1

            print(f"Case {case['id']}: Valid={result.is_valid}, "
                  f"Score={result.score:.2f}, Issues={len(result.issues)}")

        quality_rate = valid_count / total_count
        print(f"Content Quality Rate: {quality_rate:.2%} ({valid_count}/{total_count})")

        # ëª©í‘œ: 80% ì´ìƒ í’ˆì§ˆ í†µê³¼
        assert quality_rate >= 0.80, f"ì½˜í…ì¸  í’ˆì§ˆì´ ëª©í‘œì¹˜(80%)ë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤: {quality_rate:.2%}"


class TestGradingSystem:
    """ì±„ì  ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""

    def test_partial_scoring(self):
        """ë¶€ë¶„ì ìˆ˜ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
        grader = EnhancedGrader()

        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: ì •ë‹µê³¼ ìœ ì‚¬í•œ ë‹µë³€ë“¤
        test_cases = [
            {
                "user_answer": "ë„ì‹œ ë…¹í™”ëŠ” í™˜ê²½ ë¬¸ì œ í•´ê²°ì˜ í•µì‹¬ì´ë‹¤",
                "correct_answer": "ë„ì‹œ ë…¹í™”ëŠ” í™˜ê²½ ë¬¸ì œ í•´ê²°ì˜ í•µì‹¬ ë°©ë²•ì´ë‹¤",
                "expected_min_score": 85  # ê±°ì˜ ì •í™•
            },
            {
                "user_answer": "í™˜ê²½ì„ ê°œì„ í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤",
                "correct_answer": "ë„ì‹œ ë…¹í™”ëŠ” í™˜ê²½ ë¬¸ì œ í•´ê²°ì˜ í•µì‹¬ ë°©ë²•ì´ë‹¤",
                "expected_min_score": 40  # ë¶€ë¶„ ê´€ë ¨
            },
            {
                "user_answer": "ì™„ì „íˆ ë‹¤ë¥¸ ë‚´ìš©ì´ë‹¤",
                "correct_answer": "ë„ì‹œ ë…¹í™”ëŠ” í™˜ê²½ ë¬¸ì œ í•´ê²°ì˜ í•µì‹¬ ë°©ë²•ì´ë‹¤",
                "expected_max_score": 30  # ë¹„ê´€ë ¨
            }
        ]

        for i, case in enumerate(test_cases):
            result = grader.grade_topic_sentence(
                user_answer=case["user_answer"],
                correct_answer=case["correct_answer"],
                context_keywords=["ë„ì‹œ", "ë…¹í™”", "í™˜ê²½", "í•´ê²°"]
            )

            print(f"Test Case {i+1}: Score={result.score}, Band={result.band}")
            print(f"  Components: {result.components}")
            print(f"  Feedback: {result.feedback}")

            # ì ìˆ˜ ë²”ìœ„ ê²€ì¦
            if "expected_min_score" in case:
                assert result.score >= case["expected_min_score"], \
                    f"ì ìˆ˜ê°€ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤: {result.score} < {case['expected_min_score']}"

            if "expected_max_score" in case:
                assert result.score <= case["expected_max_score"], \
                    f"ì ìˆ˜ê°€ ë„ˆë¬´ ë†’ìŠµë‹ˆë‹¤: {result.score} > {case['expected_max_score']}"


class TestSystemIntegration:
    """ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸"""

    def test_end_to_end_pipeline(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
        for case in GOLDEN_CASES[:2]:  # ì²˜ìŒ 2ê°œ ì¼€ì´ìŠ¤ë§Œ í…ŒìŠ¤íŠ¸
            print(f"\n=== Testing {case['id']} ===")

            # 1. í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = extract_keywords(case["sentences"])
            print(f"Extracted keywords: {keywords}")

            # 2. ì¤‘ì‹¬ë¬¸ì¥ ì„ íƒ
            topic_result = select_topic_sentence(
                sentences=case["sentences"],
                keywords=keywords,
                genre=case["genre"]
            )
            print(f"Selected sentence: {topic_result.idx} (score: {topic_result.total:.3f})")

            # 3. ì½˜í…ì¸  ê²€ì¦
            validation_result = validate_content(case["sentences"], keywords)
            print(f"Validation: {validation_result.is_valid} (score: {validation_result.score:.3f})")

            # 4. ì±„ì  í…ŒìŠ¤íŠ¸
            grader = EnhancedGrader()
            correct_sentence = case["sentences"][case["expected_topic_sentence"]]
            user_answer = case["sentences"][topic_result.idx]

            grading_result = grader.grade_topic_sentence(
                user_answer=user_answer,
                correct_answer=correct_sentence,
                context_keywords=keywords
            )
            print(f"Grading: {grading_result.score} ({grading_result.band})")

            # ê¸°ë³¸ ê±´ì „ì„± ì²´í¬
            assert len(keywords) > 0, "í‚¤ì›Œë“œê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            assert 0 <= topic_result.idx < len(case["sentences"]), "ì¤‘ì‹¬ë¬¸ì¥ ì¸ë±ìŠ¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"
            assert validation_result.score > 0, "ê²€ì¦ ì ìˆ˜ê°€ 0ì…ë‹ˆë‹¤"
            assert grading_result.score >= 0, "ì±„ì  ì ìˆ˜ê°€ ìŒìˆ˜ì…ë‹ˆë‹¤"

        print("\nâœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    # ê°œë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    import subprocess

    print("ğŸš€ Golden Mini Dataset í…ŒìŠ¤íŠ¸ ì‹œì‘\n")

    # pytestë¡œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    result = subprocess.run([
        "python", "-m", "pytest", __file__, "-v", "--tb=short"
    ], capture_output=True, text=True)

    print(result.stdout)
    if result.stderr:
        print("Errors:", result.stderr)

    print(f"\ní…ŒìŠ¤íŠ¸ ê²°ê³¼: {'âœ… ì„±ê³µ' if result.returncode == 0 else 'âŒ ì‹¤íŒ¨'}")